{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "360179af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harshinderchadha/oratio/env/lib/python3.9/site-packages/malaya_boilerplate/frozen_graph.py:35: UserWarning: Cannot import beam_search_ops from Tensorflow Addons, ['malaya.jawi_rumi.deep_model', 'malaya.phoneme.deep_model', 'malaya.rumi_jawi.deep_model', 'malaya.stem.deep_model'] will not available to use, make sure Tensorflow Addons version >= 0.12.0\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import noisereduce as nr\n",
    "import malaya_speech \n",
    "import tensorflow as tf\n",
    "import pickle \n",
    "\n",
    "PATH = '../data/raw/speech_commands_v0.01/'\n",
    "TEST_PATH = PATH + 'testing_list.txt'\n",
    "VAL_PATH = PATH + 'validation_list.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e581fc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Oratio:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = tf.keras.models.load_model('../models/oratio_model.h5')\n",
    "        with open(\"../models/le.obj\",'rb') as f:\n",
    "            self.le = pickle.load(f)\n",
    "    \n",
    "    def prepare_data(self, filename):\n",
    "\n",
    "        sr=16000\n",
    "        vad = malaya_speech.vad.webrtc()\n",
    "        samples, sample_rate = librosa.load(filename, sr=16000)\n",
    "        samples = nr.reduce_noise(y=samples, sr=1600, stationary=True)\n",
    "        y_ = malaya_speech.resample(samples, sr, 16000)\n",
    "        y_ = malaya_speech.astype.float_to_int(y_)\n",
    "        frames = malaya_speech.generator.frames(samples, 30, sr)\n",
    "        frames_ = list(malaya_speech.generator.frames(y_, 30, 16000, append_ending_trail=False))\n",
    "        frames_webrtc = [(frames[no], vad(frame)) for no, frame in enumerate(frames_)]\n",
    "        y_ = malaya_speech.combine.without_silent(frames_webrtc)\n",
    "        zero = np.zeros(((sr+4000)-y_.shape[0]))\n",
    "        signal = np.concatenate((y_, zero))\n",
    "    \n",
    "        return signal\n",
    "    \n",
    "    def extract_mfcc(self, array):\n",
    "\n",
    "        mfcc_feat = librosa.feature.mfcc(y=array, sr=16000, n_mfcc=13)\n",
    "        mfccs = np.array([mfcc_feat.flatten()])\n",
    "\n",
    "        return None \n",
    "    \n",
    "    def predict(self, filename):\n",
    "        \n",
    "        signal = self.prepare_data(filename=filename)\n",
    "        mfcc_input = self.extract_mfcc(array=signal)\n",
    "        output = self.model.predict(mfcc_input)\n",
    "        index = np.argmax(output[0])\n",
    "        prediction = self.le.inverse_transform([index])[0]\n",
    "\n",
    "        return prediction \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dffe6c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/harshinderchadha/oratio/notebooks/data_new.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/harshinderchadha/oratio/notebooks/data_new.ipynb#ch0000030?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m Oratio()\n",
      "\u001b[1;32m/Users/harshinderchadha/oratio/notebooks/data_new.ipynb Cell 2'\u001b[0m in \u001b[0;36mOratio.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/harshinderchadha/oratio/notebooks/data_new.ipynb#ch0000029?line=3'>4</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(\u001b[39m'\u001b[39m\u001b[39m../models/oratio_model.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/harshinderchadha/oratio/notebooks/data_new.ipynb#ch0000029?line=4'>5</a>\u001b[0m file \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m../models/le.obj\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/harshinderchadha/oratio/notebooks/data_new.ipynb#ch0000029?line=5'>6</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mle \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(file)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/harshinderchadha/oratio/notebooks/data_new.ipynb#ch0000029?line=6'>7</a>\u001b[0m file\u001b[39m.\u001b[39mclose()\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "model = Oratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fd336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = model.prepare_data(filename='../data/upload/0e5193e6_nohash_1.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b08fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs = model.extract_mfcc(array=signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd13b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(mfccs)\n",
    "# data = data.reshape(np.array(mfccs).shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91e0d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([mfccs.flatten()]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3229712b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864ce1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commands():\n",
    "    exempt_list = [\n",
    "    '.DS_Store', 'validation_list.txt', 'LICENSE',\n",
    "    '_background_noise_', 'README.md', 'testing_list.txt'\n",
    "]\n",
    "\n",
    "    commands = get_directory_content(path=PATH)\n",
    "    commands = [command for command in commands if command not in exempt_list]\n",
    "\n",
    "    return commands \n",
    "\n",
    "def get_directory_content(path):\n",
    "    return os.listdir(path)\n",
    "\n",
    "def open_file(filename):\n",
    "    \n",
    "    f = open(filename)\n",
    "    return f.read().splitlines()\n",
    "\n",
    "def compile_dataset():\n",
    "\n",
    "    commands = get_commands()\n",
    "\n",
    "    filenames = []\n",
    "    for command in commands:\n",
    "        recordings = get_directory_content(path=PATH+command)\n",
    "        recordings = [command+'/'+recording for recording in recordings]\n",
    "        filenames = filenames + recordings\n",
    "                             \n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae16045",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = compile_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e71af",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, sample_rate = librosa.load(PATH+files[0], sr=16000)\n",
    "fig = plt.figure(figsize=(14,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.set_title(f\"Raw wave of {files[0]}\")\n",
    "ax1.set_xlabel('time')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.plot(np.linspace(0, sample_rate/len(samples), sample_rate), samples)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf2bd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 16000\n",
    "sr = fs\n",
    "ipd.Audio(samples, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844bd824",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.linspace(0, len(samples-1)/fs, len(samples -1))\n",
    "no_noise = nr.reduce_noise(y=samples, sr=fs, stationary=True)\n",
    "plt.figure(figsize=(14,8))\n",
    "plt.plot(time, no_noise)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e90bfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(no_noise, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1647a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vad = malaya_speech.vad.webrtc()\n",
    "y = no_noise\n",
    "y_ = malaya_speech.resample(y, sr, 16000)\n",
    "y_ = malaya_speech.astype.float_to_int(y_)\n",
    "frames = malaya_speech.generator.frames(y, 30, sr)\n",
    "frames_ = list(malaya_speech.generator.frames(y_, 30, 16000, append_ending_trail=False))\n",
    "frames_webrtc = [(frames[no], vad(frame)) for no, frame in enumerate(frames_)]\n",
    "y_ = malaya_speech.combine.without_silent(frames_webrtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144a8598",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(y_, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a96a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = np.zeros((1*sr-y_.shape[0]))\n",
    "signal = np.concatenate((y_, zero))\n",
    "signal.shape\n",
    "time = np.linspace(0, len(signal-1)/fs, len(signal-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f594a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time, signal)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f347a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = open_file(TEST_PATH)\n",
    "validation_files = open_file(VAL_PATH)\n",
    "train_files = list(set(files).difference(set(test_files+validation_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbba32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(filenames):\n",
    "    \n",
    "    sr=16000\n",
    "    vad = malaya_speech.vad.webrtc()\n",
    "    data = [None] * len(filenames)\n",
    "    labels = [None] * len(filenames)\n",
    "    for i, file in enumerate(filenames):\n",
    "        samples, sample_rate = librosa.load(PATH+file, sr=16000)\n",
    "        samples = nr.reduce_noise(y=samples, sr=fs, stationary=True)\n",
    "        y_ = malaya_speech.resample(samples, sr, 16000)\n",
    "        y_ = malaya_speech.astype.float_to_int(y_)\n",
    "        frames = malaya_speech.generator.frames(samples, 30, sr)\n",
    "        frames_ = list(malaya_speech.generator.frames(y_, 30, 16000, append_ending_trail=False))\n",
    "        frames_webrtc = [(frames[no], vad(frame)) for no, frame in enumerate(frames_)]\n",
    "        y_ = malaya_speech.combine.without_silent(frames_webrtc)\n",
    "        zero = np.zeros(((sr+4000)-y_.shape[0]))\n",
    "        signal = np.concatenate((y_, zero))\n",
    "        \n",
    "        data[i] = signal\n",
    "        labels[i] = file.split('/')[0]\n",
    "    \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263945ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test_data, test_labels = prepare_dataset(filenames=test_files[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9c40de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "val_data, val_labels = prepare_dataset(filenames=validation_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d44fb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_data, train_labels = prepare_dataset(filenames=train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5333e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc(data):\n",
    "    fs = 16000\n",
    "    mfccs = [None]*len(data)\n",
    "    for i, array in enumerate(data):\n",
    "        \n",
    "#         mfcc_feat = mfcc(array , fs, winlen=256/fs, winstep=256/(2*fs), numcep=13, nfilt=26, nfft=256,\n",
    "#                  lowfreq=0, highfreq=fs/2, preemph=0.97, ceplifter=22, appendEnergy=True, winfunc=np.hamming)\n",
    "#         mfcc_feat= np.transpose(mfcc_feat)\n",
    "        \n",
    "        mfcc_feat = librosa.feature.mfcc(y=array, sr=fs, n_mfcc=13)\n",
    "        mfccs[i] = mfcc_feat\n",
    "    \n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b20bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_mfcc = extract_mfcc(data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53532fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "val_mfcc = extract_mfcc(data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807f7d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_mfcc = extract_mfcc(data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca62f94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_array(mfccs):\n",
    "    data = np.array(mfccs)\n",
    "    data = data.reshape(np.array(mfccs).shape[0], -1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1bc56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = reshape_array(mfccs=train_mfcc)\n",
    "# val = reshape_array(mfccs=val_mfcc)\n",
    "test = reshape_array(mfccs=test_mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b8c205",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(train)\n",
    "val = pd.DataFrame(val)\n",
    "test = pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c94f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['labels'] = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf74c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "val['labels'] = val_labels\n",
    "test['labels'] = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5badea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv', index=False)\n",
    "val.to_csv('val.csv', index=False)\n",
    "test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8da5bff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oratio",
   "language": "python",
   "name": "oratio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "a824a5e37c18a5a9b217bb28126ad56c48aa31931a52b884c328b18c439a33d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
