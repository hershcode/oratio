{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "from scipy.io import wavfile as wav\n",
    "from sklearn import metrics \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.getcwd() + '/speech_commands_v0.01/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directory_contents(path):\n",
    "    return os.listdir(path)\n",
    "\n",
    "def open_file(filename):\n",
    "    \n",
    "    f = open(filename)\n",
    "    return f.read().splitlines()\n",
    "\n",
    "def compile_dataset(folders):\n",
    "    \n",
    "    total_words = []\n",
    "    for folder in folders:\n",
    "        words = get_directory_contents(path=PATH+folder)\n",
    "        words = [folder+'/'+word for word in words]\n",
    "        total_words = total_words + words\n",
    "    \n",
    "    dataset = create_df(words=total_words)\n",
    "                           \n",
    "    return dataset\n",
    "\n",
    "def create_df(words):\n",
    "    \n",
    "    data = pd.DataFrame({'recordings':words})\n",
    "\n",
    "    data['word'] = data['recordings'].str.split('/').str[0]\n",
    "    data['speaker_id'] = data['recordings'].str.split('/').str[1]\n",
    "    data['speaker_id'] =data['speaker_id'].str.split('_').str[0]\n",
    "    \n",
    "    return data\n",
    "\n",
    "def summary(data):\n",
    "    \n",
    "    summary_df = pd.DataFrame()\n",
    "    summary_df['total_recordings'] = [data.shape[0]]\n",
    "    summary_df['total_speakers'] = len(data['speaker_id'].unique())\n",
    "    summary_df['total_words'] = len(data['word'].unique())\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "def word_distribution():\n",
    "    \n",
    "    word_count = data['word'].value_counts()\n",
    "    ax = word_count.plot(kind='bar', figsize=(8,4), alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_words = [\n",
    "    '.DS_Store', 'validation_list.txt', 'LICENSE',\n",
    "    '_background_noise_', 'README.md', 'testing_list.txt'\n",
    "]\n",
    "\n",
    "names = get_directory_contents(path=PATH)\n",
    "names = [word for word in names if word not in remove_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_list = open_file(filename=PATH+'validation_list.txt')\n",
    "val_df = create_df(words=val_list)\n",
    "test_list = open_file(filename=PATH+'testing_list.txt')\n",
    "test_df = create_df(words=test_list)\n",
    "total_df = compile_dataset(folders=names)\n",
    "\n",
    "training_df = total_df[~total_df['recordings'].isin(val_df['recordings'])]\n",
    "training_df = training_df[~training_df['recordings'].isin(test_df['recordings'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample rate: 16000\n",
      "Librosa sample rate: 22050\n"
     ]
    }
   ],
   "source": [
    "fn = 'speech_commands_v0.01/four/10c6d873_nohash_0.wav'\n",
    "librosa_audio, librosa_sample_rate = librosa.load(fn)\n",
    "scipy_sample_rate, scipy_audio = wav.read(fn)\n",
    "print(\"Original sample rate: {}\".format(scipy_sample_rate))\n",
    "print(\"Librosa sample rate: {}\".format(librosa_sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original audio file min~max range: -32768 to 16883\n",
      "Librosa audio file min~max range: -1.00 to -1.00\n"
     ]
    }
   ],
   "source": [
    "print('Original audio file min~max range: {} to {}'.format(np.min(scipy_audio), np.max(scipy_audio)))\n",
    "print('Librosa audio file min~max range: {0:.2f} to {0:.2f}'.format(np.min(librosa_audio), np.max(librosa_audio)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs = librosa.feature.mfcc(y=librosa_audio, sr=librosa_sample_rate, n_mfcc = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_name):\n",
    "    audio, sample_rate = librosa.load(file_name) \n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_processed = np.mean(mfccs.T,axis=0)\n",
    "     \n",
    "    return mfccs_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_prep(df):\n",
    "    features = []\n",
    "    # Iterate through each sound file and extract the features \n",
    "    for index, row in df.iterrows():\n",
    "        file_name = 'speech_commands_v0.01/'+row['recordings']\n",
    "        class_label = row[\"word\"]\n",
    "        data = extract_features(file_name)\n",
    "\n",
    "        features.append([data, class_label])\n",
    "    # Convert into a Panda dataframe \n",
    "    featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "    return featuresdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresdf = dataset_prep(df=training_df)\n",
    "featuresdf.to_csv(\"training_set.csv\")\n",
    "\n",
    "testdf = dataset_prep(df=test_df)\n",
    "valdf = dataset_prep(df=val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf.to_csv(\"testdf.csv\")\n",
    "valdf.to_csv(\"validation_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "y = np.array(featuresdf.class_label.tolist())\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y))\n",
    "\n",
    "x_val = np.array(valdf.feature.tolist())\n",
    "y_val = np.array(valdf.class_label.tolist())\n",
    "y_val = to_categorical(le.transform(y_val))\n",
    "\n",
    "x_test = np.array(testdf.feature.tolist())\n",
    "y_test = np.array(testdf.class_label.tolist())\n",
    "y_test = to_categorical(le.transform(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = yy.shape[1]\n",
    "filter_size = 2\n",
    "def build_model_graph(input_shape=(40,)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30))\n",
    "    model.add(Activation('relu'))\n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "    return model\n",
    "model = build_model_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 7.2422 - accuracy: 0.0560 - val_loss: 6.4439 - val_accuracy: 0.1091\n",
      "Epoch 2/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 6.4780 - accuracy: 0.1159 - val_loss: 6.3437 - val_accuracy: 0.1478\n",
      "Epoch 3/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 6.4240 - accuracy: 0.1387 - val_loss: 6.2718 - val_accuracy: 0.1586\n",
      "Epoch 4/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 6.1035 - accuracy: 0.1480 - val_loss: 5.9083 - val_accuracy: 0.1606\n",
      "Epoch 5/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8574 - accuracy: 0.1546 - val_loss: 5.8876 - val_accuracy: 0.1590\n",
      "Epoch 6/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8908 - accuracy: 0.1639 - val_loss: 5.8880 - val_accuracy: 0.1709\n",
      "Epoch 7/100\n",
      "1597/1597 [==============================] - 2s 988us/step - loss: 5.8915 - accuracy: 0.1734 - val_loss: 5.8768 - val_accuracy: 0.2043\n",
      "Epoch 8/100\n",
      "1597/1597 [==============================] - 2s 964us/step - loss: 5.8815 - accuracy: 0.1731 - val_loss: 5.8673 - val_accuracy: 0.1846\n",
      "Epoch 9/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8628 - accuracy: 0.1834 - val_loss: 5.8562 - val_accuracy: 0.1731\n",
      "Epoch 10/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8605 - accuracy: 0.1672 - val_loss: 5.8590 - val_accuracy: 0.1614\n",
      "Epoch 11/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8624 - accuracy: 0.1659 - val_loss: 5.8849 - val_accuracy: 0.1773\n",
      "Epoch 12/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8307 - accuracy: 0.1791 - val_loss: 5.8732 - val_accuracy: 0.1967\n",
      "Epoch 13/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.7976 - accuracy: 0.1836 - val_loss: 5.8605 - val_accuracy: 0.2018\n",
      "Epoch 14/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.7824 - accuracy: 0.1920 - val_loss: 5.8477 - val_accuracy: 0.1926\n",
      "Epoch 15/100\n",
      "1597/1597 [==============================] - 4s 2ms/step - loss: 5.8491 - accuracy: 0.1830 - val_loss: 5.8529 - val_accuracy: 0.1974\n",
      "Epoch 16/100\n",
      "1597/1597 [==============================] - 4s 2ms/step - loss: 5.8479 - accuracy: 0.1874 - val_loss: 5.8564 - val_accuracy: 0.2095\n",
      "Epoch 17/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8590 - accuracy: 0.1969 - val_loss: 5.9071 - val_accuracy: 0.1696\n",
      "Epoch 18/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8475 - accuracy: 0.1855 - val_loss: 5.8609 - val_accuracy: 0.1871\n",
      "Epoch 19/100\n",
      "1597/1597 [==============================] - 2s 977us/step - loss: 5.8545 - accuracy: 0.1895 - val_loss: 5.8662 - val_accuracy: 0.2059\n",
      "Epoch 20/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8555 - accuracy: 0.1939 - val_loss: 5.8599 - val_accuracy: 0.2017\n",
      "Epoch 21/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8992 - accuracy: 0.1959 - val_loss: 5.8655 - val_accuracy: 0.1878\n",
      "Epoch 22/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8202 - accuracy: 0.1895 - val_loss: 5.8585 - val_accuracy: 0.1946\n",
      "Epoch 23/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8513 - accuracy: 0.1919 - val_loss: 5.8634 - val_accuracy: 0.1974\n",
      "Epoch 24/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8518 - accuracy: 0.1876 - val_loss: 5.8495 - val_accuracy: 0.1936\n",
      "Epoch 25/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8341 - accuracy: 0.1919 - val_loss: 5.8421 - val_accuracy: 0.2109\n",
      "Epoch 26/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8202 - accuracy: 0.1986 - val_loss: 5.8519 - val_accuracy: 0.2201\n",
      "Epoch 27/100\n",
      "1597/1597 [==============================] - 2s 973us/step - loss: 5.8296 - accuracy: 0.2016 - val_loss: 5.8504 - val_accuracy: 0.2030\n",
      "Epoch 28/100\n",
      "1597/1597 [==============================] - 2s 977us/step - loss: 5.8209 - accuracy: 0.1920 - val_loss: 5.8533 - val_accuracy: 0.2123\n",
      "Epoch 29/100\n",
      "1597/1597 [==============================] - 2s 959us/step - loss: 5.8528 - accuracy: 0.1949 - val_loss: 5.8488 - val_accuracy: 0.2036\n",
      "Epoch 30/100\n",
      "1597/1597 [==============================] - 2s 951us/step - loss: 5.8242 - accuracy: 0.1989 - val_loss: 5.8561 - val_accuracy: 0.2098\n",
      "Epoch 31/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8595 - accuracy: 0.2005 - val_loss: 5.8710 - val_accuracy: 0.1933\n",
      "Epoch 32/100\n",
      "1597/1597 [==============================] - 4s 2ms/step - loss: 5.7990 - accuracy: 0.1947 - val_loss: 5.8546 - val_accuracy: 0.2130\n",
      "Epoch 33/100\n",
      "1597/1597 [==============================] - 3s 2ms/step - loss: 5.7662 - accuracy: 0.2024 - val_loss: 5.8577 - val_accuracy: 0.2071\n",
      "Epoch 34/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8258 - accuracy: 0.1953 - val_loss: 5.8505 - val_accuracy: 0.2123\n",
      "Epoch 35/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8194 - accuracy: 0.1961 - val_loss: 5.8628 - val_accuracy: 0.2061\n",
      "Epoch 36/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8752 - accuracy: 0.1919 - val_loss: 5.8559 - val_accuracy: 0.2149\n",
      "Epoch 37/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8270 - accuracy: 0.2047 - val_loss: 5.8566 - val_accuracy: 0.1971\n",
      "Epoch 38/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8008 - accuracy: 0.1985 - val_loss: 5.8897 - val_accuracy: 0.2058\n",
      "Epoch 39/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8032 - accuracy: 0.2050 - val_loss: 5.8493 - val_accuracy: 0.2209\n",
      "Epoch 40/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.7771 - accuracy: 0.2000 - val_loss: 5.8764 - val_accuracy: 0.2170\n",
      "Epoch 41/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8052 - accuracy: 0.2019 - val_loss: 5.8527 - val_accuracy: 0.2055\n",
      "Epoch 42/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8312 - accuracy: 0.2014 - val_loss: 5.8550 - val_accuracy: 0.2048\n",
      "Epoch 43/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8136 - accuracy: 0.1956 - val_loss: 5.8543 - val_accuracy: 0.2180\n",
      "Epoch 44/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8089 - accuracy: 0.2036 - val_loss: 5.8575 - val_accuracy: 0.2052\n",
      "Epoch 45/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8211 - accuracy: 0.1934 - val_loss: 5.8582 - val_accuracy: 0.2049\n",
      "Epoch 46/100\n",
      "1597/1597 [==============================] - 2s 2ms/step - loss: 5.8416 - accuracy: 0.1960 - val_loss: 5.8506 - val_accuracy: 0.1996\n",
      "Epoch 47/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.7792 - accuracy: 0.1974 - val_loss: 5.8664 - val_accuracy: 0.1987\n",
      "Epoch 48/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8087 - accuracy: 0.1870 - val_loss: 5.8658 - val_accuracy: 0.1771\n",
      "Epoch 49/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.7998 - accuracy: 0.1820 - val_loss: 5.8755 - val_accuracy: 0.2005\n",
      "Epoch 50/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8144 - accuracy: 0.1939 - val_loss: 5.8348 - val_accuracy: 0.1948\n",
      "Epoch 51/100\n",
      "1597/1597 [==============================] - 2s 998us/step - loss: 5.7736 - accuracy: 0.1960 - val_loss: 5.8638 - val_accuracy: 0.2017\n",
      "Epoch 52/100\n",
      "1597/1597 [==============================] - 3s 2ms/step - loss: 5.8248 - accuracy: 0.1964 - val_loss: 5.8402 - val_accuracy: 0.1993\n",
      "Epoch 53/100\n",
      "1597/1597 [==============================] - 5s 3ms/step - loss: 5.8060 - accuracy: 0.2003 - val_loss: 5.8552 - val_accuracy: 0.1937\n",
      "Epoch 54/100\n",
      "1597/1597 [==============================] - 4s 2ms/step - loss: 5.8494 - accuracy: 0.1864 - val_loss: 5.8771 - val_accuracy: 0.1981\n",
      "Epoch 55/100\n",
      "1597/1597 [==============================] - 2s 2ms/step - loss: 5.8100 - accuracy: 0.1924 - val_loss: 5.8584 - val_accuracy: 0.1984\n",
      "Epoch 56/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8425 - accuracy: 0.1928 - val_loss: 5.8719 - val_accuracy: 0.1959\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.7961 - accuracy: 0.1991 - val_loss: 5.8642 - val_accuracy: 0.2045\n",
      "Epoch 58/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8131 - accuracy: 0.2046 - val_loss: 5.8655 - val_accuracy: 0.2107\n",
      "Epoch 59/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8000 - accuracy: 0.2027 - val_loss: 5.8587 - val_accuracy: 0.2114\n",
      "Epoch 60/100\n",
      "1597/1597 [==============================] - 2s 977us/step - loss: 5.8462 - accuracy: 0.2042 - val_loss: 5.8835 - val_accuracy: 0.2071\n",
      "Epoch 61/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8199 - accuracy: 0.2050 - val_loss: 5.8766 - val_accuracy: 0.2118\n",
      "Epoch 62/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8008 - accuracy: 0.2058 - val_loss: 5.8400 - val_accuracy: 0.2046\n",
      "Epoch 63/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.7581 - accuracy: 0.2056 - val_loss: 5.8680 - val_accuracy: 0.2121\n",
      "Epoch 64/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8057 - accuracy: 0.1982 - val_loss: 5.8540 - val_accuracy: 0.2173\n",
      "Epoch 65/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.7699 - accuracy: 0.2055 - val_loss: 5.9022 - val_accuracy: 0.2112\n",
      "Epoch 66/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8224 - accuracy: 0.2026 - val_loss: 5.8735 - val_accuracy: 0.2151\n",
      "Epoch 67/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8004 - accuracy: 0.2032 - val_loss: 5.8424 - val_accuracy: 0.2074\n",
      "Epoch 68/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.7963 - accuracy: 0.1961 - val_loss: 5.8641 - val_accuracy: 0.2124\n",
      "Epoch 69/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8237 - accuracy: 0.2006 - val_loss: 5.8979 - val_accuracy: 0.2058\n",
      "Epoch 70/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.7785 - accuracy: 0.2039 - val_loss: 5.8672 - val_accuracy: 0.2071\n",
      "Epoch 71/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8168 - accuracy: 0.2010 - val_loss: 5.8796 - val_accuracy: 0.2045\n",
      "Epoch 72/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.7789 - accuracy: 0.1999 - val_loss: 5.8660 - val_accuracy: 0.1995\n",
      "Epoch 73/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8007 - accuracy: 0.1990 - val_loss: 5.8619 - val_accuracy: 0.2108\n",
      "Epoch 74/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.7994 - accuracy: 0.2075 - val_loss: 5.8594 - val_accuracy: 0.2140\n",
      "Epoch 75/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.7626 - accuracy: 0.2057 - val_loss: 5.8776 - val_accuracy: 0.2155\n",
      "Epoch 76/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8171 - accuracy: 0.2047 - val_loss: 5.8644 - val_accuracy: 0.2112\n",
      "Epoch 77/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8524 - accuracy: 0.2041 - val_loss: 5.8597 - val_accuracy: 0.2034\n",
      "Epoch 78/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.7949 - accuracy: 0.1980 - val_loss: 5.8730 - val_accuracy: 0.2124\n",
      "Epoch 79/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.7934 - accuracy: 0.1959 - val_loss: 5.8693 - val_accuracy: 0.2098\n",
      "Epoch 80/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8375 - accuracy: 0.1998 - val_loss: 5.8821 - val_accuracy: 0.1986\n",
      "Epoch 81/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8143 - accuracy: 0.2023 - val_loss: 5.8927 - val_accuracy: 0.2158\n",
      "Epoch 82/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.7989 - accuracy: 0.2038 - val_loss: 5.8768 - val_accuracy: 0.2109\n",
      "Epoch 83/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8104 - accuracy: 0.2031 - val_loss: 5.8692 - val_accuracy: 0.2111\n",
      "Epoch 84/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8252 - accuracy: 0.2065 - val_loss: 5.8632 - val_accuracy: 0.2183\n",
      "Epoch 85/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8275 - accuracy: 0.2037 - val_loss: 5.8633 - val_accuracy: 0.2014\n",
      "Epoch 86/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8536 - accuracy: 0.1952 - val_loss: 5.8758 - val_accuracy: 0.2064\n",
      "Epoch 87/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.7781 - accuracy: 0.2053 - val_loss: 5.8641 - val_accuracy: 0.2027\n",
      "Epoch 88/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8158 - accuracy: 0.1990 - val_loss: 5.8808 - val_accuracy: 0.2051\n",
      "Epoch 89/100\n",
      "1597/1597 [==============================] - 3s 2ms/step - loss: 5.8186 - accuracy: 0.2082 - val_loss: 5.8717 - val_accuracy: 0.2124\n",
      "Epoch 90/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8035 - accuracy: 0.2002 - val_loss: 5.8652 - val_accuracy: 0.2117\n",
      "Epoch 91/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.7813 - accuracy: 0.2035 - val_loss: 5.8503 - val_accuracy: 0.2126\n",
      "Epoch 92/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.7560 - accuracy: 0.2054 - val_loss: 5.8829 - val_accuracy: 0.2070\n",
      "Epoch 93/100\n",
      "1597/1597 [==============================] - 3s 2ms/step - loss: 5.7934 - accuracy: 0.2037 - val_loss: 5.8687 - val_accuracy: 0.2095\n",
      "Epoch 94/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.7810 - accuracy: 0.1942 - val_loss: 5.8667 - val_accuracy: 0.2073\n",
      "Epoch 95/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.7850 - accuracy: 0.2003 - val_loss: 5.8630 - val_accuracy: 0.2012\n",
      "Epoch 96/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8097 - accuracy: 0.1984 - val_loss: 5.8512 - val_accuracy: 0.2039\n",
      "Epoch 97/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8517 - accuracy: 0.1959 - val_loss: 5.8525 - val_accuracy: 0.2081\n",
      "Epoch 98/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8570 - accuracy: 0.1987 - val_loss: 5.8637 - val_accuracy: 0.2029\n",
      "Epoch 99/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.8016 - accuracy: 0.2013 - val_loss: 5.8669 - val_accuracy: 0.2061\n",
      "Epoch 100/100\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 5.7935 - accuracy: 0.2029 - val_loss: 5.8928 - val_accuracy: 0.1995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x155aff160>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "model.fit(X, yy, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_val, y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 19.96%\n",
      "Validation Accuracy: 19.95%\n",
      "Testing Accuracy: 18.95%\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X, yy, verbose=0)\n",
    "print(\"Training Accuracy: {0:.2%}\".format(score[1]))\n",
    "score = model.evaluate(x_val, y_val, verbose=0)\n",
    "print(\"Validation Accuracy: {0:.2%}\".format(score[1]))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: {0:.2%}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Machine Learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(multi_class='multinomial', solver='newton-cg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_category(columns, dataframe):\n",
    "    \"\"\"Convert a list of columns, from a dataframe, to a category datatype\"\"\"\n",
    "    for column in columns: \n",
    "        dataframe[column] = dataframe[column].astype('category')\n",
    "    return dataframe\n",
    "columns=['word']\n",
    "\n",
    "training_df = to_category(columns=columns, dataframe=training_df)\n",
    "test_df = to_category(columns=columns, dataframe=test_df)\n",
    "val_df = to_category(columns=columns, dataframe=val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harshinderchadha/general/lib/python3.8/site-packages/sklearn/utils/optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 29.40%\n",
      "Validation Accuracy: 29.07%\n",
      "Testing Accuracy: 26.53%\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X, training_df['word'])\n",
    "\n",
    "print(\"Training Accuracy: {0:.2%}\".format(clf.score(X, training_df['word'])))\n",
    "print(\"Validation Accuracy: {0:.2%}\".format(clf.score(x_val, val_df['word'])))\n",
    "print(\"Testing Accuracy: {0:.2%}\".format(clf.score(x_test, test_df['word'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "general"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
